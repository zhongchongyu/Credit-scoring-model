{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "# 将 NN 的预测结果（array 的 array 转化成 list）\n",
    "def NNPre_to_list(NN_pre):\n",
    "    pre = []\n",
    "    for i in range(len(NN_pre)):\n",
    "        pre.append(NN_pre[i][0])    \n",
    "    return pre\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    set_random_seed(int(time.time()))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=300,activation='softsign', input_dim=np.shape(train)[1]-2))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(units=50))\n",
    "    model.add(Activation(\"softsign\"))\n",
    "    model.add(Dropout(0.15))\n",
    "    \n",
    "    # 输出节点\n",
    "    model.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "    \n",
    "    # 编译网络\n",
    "    sgd = optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "    adma = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    Adamax = optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='Adamax', \n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'D:/DataSet/Credit/'\n",
    "train = pd.read_csv(base_path + 'featured/train_all_feature_log.csv')\n",
    "test = pd.read_csv(base_path + 'featured/test_all_feature_log.csv')\n",
    "\n",
    "one_hot = 0\n",
    "if one_hot:\n",
    "    train = pd.get_dummies(train)\n",
    "    test = pd.get_dummies(test)\n",
    "    \n",
    "col_to_drop = [\n",
    "    # 1\n",
    "    'count_house_loan_ln',# 0.97232912500359225)\n",
    "    'count_house_loan',# 0.65395611105534779)\n",
    "    'edu_level_other',# 0.57350198625873861)\n",
    "    'count_payment_state_E_ln',# 0.51044888053676218)\n",
    "    'count_attention_ln',# 0.32350891467937332)\n",
    "    'count_commercial_loan',# 0.0)\n",
    "    'count_sixty_ovd_dw',# 0.0)\n",
    "    'count_sixty_ovd_months',# 0.0)\n",
    "    'ind_sixty_max_duration',# 0.0)\n",
    "    'marry_status_other',# 0.0)\n",
    "    'count_study_loan_ln',# 0.0)\n",
    "    'count_housing_accumulation_ln',# 0.0)\n",
    "    'count_commercial_housing_ln',# 0.0)\n",
    "    'count_combination_ensure_ln',# 0.0)\n",
    "    'ind_other_counts_lnd',# 0.0)\n",
    "    'count_combination_lnd',# 0.0)\n",
    "    'count_pledge_guarantee_lnd',# 0.0)\n",
    "    'count_ensure_lnd',# 0.0)\n",
    "    'count_other_guarantee_lnd',# 0.0)\n",
    "    'count_combination_ensure_lnd',# 0.0)\n",
    "    'count_farmer_joint_lnd',# 0.0)\n",
    "    'count_pledge_guarantee_bail_lnd',# 0.0)\n",
    "    # 10\n",
    "    'ind_curr_overdue_cyc_lnd',# 9.1747017468829988)\n",
    "    'ind_unact_counts_lnd',# 8.1829607049772104)\n",
    "    'ind_other_counts',# 8.1190294047611253)\n",
    "    'count_pledge_guarantee_bail_ln',# 4.9866824922417035)\n",
    "    'count_sharedebt',# 4.25470982342895)\n",
    "    'marry_status_unmarried',# 3.5268450817329375)\n",
    "    'count_normal_ln',# 3.1544560288384238)\n",
    "    'count_farmer_joint_ln',# 2.8250789765495536)\n",
    "    'not_clear_account_count',# 2.438362051462843)\n",
    "    'count_car_loan_ln',# 2.0244134983035815)\n",
    "    'count_payment_state_E_lnd',# 1.9511014375106948)\n",
    "    # 40\n",
    "    'ind_normal_counts',# 38.981578298058366)\n",
    "    'count_ensure_ln',# 32.686012781155711)\n",
    "    'not_logout_pre_account_count',# 29.035934862113912)\n",
    "    'count_spl',# 26.621401271906876)\n",
    "    'not_logout_pre_finance_org_count',# 20.88833411697636)\n",
    "    'count_debit_card_ovd_dw',# 20.552771641255653)\n",
    "    'ind_clear_counts_lnd',# 18.63633007759838)\n",
    "    'cat_query_reason_mal',# 18.012892273855371)\n",
    "    'count_other_guarantee_ln',# 15.719418555370231)\n",
    "    'count_pledge_guarantee_ln',# 14.603172531948651)\n",
    "    'count_standard_loancard',# 14.257967916620288)\n",
    "    'count_combination_ln',# 13.225866749150008)\n",
    "    'marry_status_divorced',# 12.996673186745294)\n",
    "    'flt_highest_sixty_oa_per_mon',# 12.496437876453976)\n",
    "    'count_farmer_loan_ln',# 12.034259912867824)\n",
    "    # 60\n",
    "    'curr_overdue_cyc_days',# 58.533138767951407)\n",
    "    'not_logout_pre_max_credit_limit_per_org',# 55.545770066417433)\n",
    "    'not_logout_pre_finance_corp_count',# 54.909995520093744)\n",
    "    'has_fund',# 53.524477466077244)\n",
    "    'edu_level_bachelor',# 51.681921368379456)\n",
    "    'cat_query_reason_sqe',# 50.507370364531575)\n",
    "    'not_clear_finance_org_count',# 50.499752342403504)\n",
    "    'count_payment_state_B_ln',# 49.675949679726415)\n",
    "    'count_ovd',# 47.284280675138668)\n",
    "    'marry_status_married',# 47.141063732728689)\n",
    "    # 100\n",
    "    'count_payment_state_D_ln',# 98.582591891500016)\n",
    "    'not_logout_finance_org_count',# 97.63379220401383)\n",
    "    'count_credit_loan_ln',# 96.057688729626022)\n",
    "    'count_payment_state_D_lnd',# 94.52677681813546)\n",
    "    'all_highest_oa_per_mon',# 93.758390716396264)\n",
    "    'count_consumption loan_ln',# 92.34403542313882)\n",
    "    'not_logout_pre_latest_6m_used_avg_amount',# 85.357040829001591)\n",
    "    'balance',# 85.186190705260103)\n",
    "    'cat_query_reason_la',# 83.737758346562558)\n",
    "    'ind_clear_counts',# 82.467554392775014)\n",
    "    'count_unknown_ln',# 73.400641666623201)\n",
    "    'not_logout_pre_min_credit_limit_per_org',# 70.752886069309909)\n",
    "    'not_logout_pre_credit_limit',# 68.394379619115668)\n",
    "    'not_logout_account_count',# 67.926934887483739)\n",
    "    'lnd_ovd_sum_amount',# 67.598474433716945)\n",
    "    'flt_highest_debit_card_oa_per_mon',# 64.9057845815354)\n",
    "    'count_loan_ovd_dw',# 64.132474960621153)\n",
    "    'count_operating_loan_ln',# 63.127772355688421)\n",
    "    'not_clear_finance_corp_count',# 62.877948676798582)\n",
    "    # 180\n",
    "    'not_logout_latest_6m_used_avg_amount',# 176.32317263727683)\n",
    "    'ind_loan_max_duration',# 167.56724876084013)\n",
    "    'count_credit_loan_lnd',# 166.96045957856194)\n",
    "    'all_max_duration',# 153.57957111737943)\n",
    "    'not_clear_balance',# 153.18548993022915)\n",
    "    'flt_highest_loan_oa_per_mon',# 150.5264464131252)\n",
    "    'flt_sum_amount',# 149.83162201460962)\n",
    "    'used_highest_amount_lnd',# 136.85598322859255)\n",
    "    'scheduled_payment_amount',# 128.02030046387119)\n",
    "    'latest6_month_used_avg_amount_lnd',# 124.58135686300396)\n",
    "    'ind_org_counts',# 120.5490321578975)\n",
    "    'ind_debit_card_max_duration',# 118.53218655429413)\n",
    "    'edu_level_junior',# 117.02178169627837)\n",
    "    'lnd_ovd_sum_last_months',# 114.74345491704378)\n",
    "    'used_credit_limit_amount_lnd',# 114.2672848868574)\n",
    "    'ave_ovd_amount',# 114.06571798355444)\n",
    "    'count_other_loan',# 111.82596886962884)\n",
    "    'range_lnd_ovd',# 109.13363916690426)\n",
    "    'not_logout_pre_used_credit_limit',# 105.64340446411771)\n",
    "    'count_sum_ovd_dw',# 104.97563024241767)\n",
    "    # flt_noise\n",
    "    'not_logout_max_credit_limit_per_org',# 211.80030432198566)\n",
    "    # 240\n",
    "    #'not_logout_finance_corp_count',# 217.97120979038462)\n",
    "]\n",
    "\n",
    "train = train.drop(col_to_drop, axis=1)\n",
    "test = test.drop(col_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NN kfold: 1  of  5 : \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3c980d4c3f20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m               \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m               \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m               callbacks = [learning_rate_reduction])\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Code\\AboutPython\\anaconda\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mD:\\Work\\Code\\AboutPython\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[1;32mD:\\Work\\Code\\AboutPython\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Code\\AboutPython\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Code\\AboutPython\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Code\\AboutPython\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Code\\AboutPython\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\Work\\Code\\AboutPython\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Code\\AboutPython\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow import set_random_seed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout,ActivityRegularization\n",
    "from keras import optimizers\n",
    "from sklearn import preprocessing\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\n",
    "\n",
    "#####################\n",
    "####### NN CV #######\n",
    "#####################\n",
    "\n",
    "# 设定结果储存位置\n",
    "y = train.y.values\n",
    "sub=test.report_id.to_frame()                      # 用于储存结果\n",
    "sub['pred']=0                                         # 初始化为 0\n",
    "sub_train=train.report_id.to_frame()\n",
    "sub_train['y']=train.y                                # oof\n",
    "sub_train['pred'] = 0\n",
    "\n",
    "# 对 train 和 test 的 X 进行标准化\n",
    "all_data = pd.concat([train.drop(['y','report_id'],axis=1), test.drop(['report_id'],axis=1)], axis=0)\n",
    "scaler = preprocessing.StandardScaler().fit(all_data)\n",
    "X_scaled_train = scaler.fit_transform(all_data[0:len(train)])\n",
    "X_scaled_test = scaler.fit_transform(all_data[len(train):])\n",
    "\n",
    "K = 5\n",
    "runs_per_fold = 3\n",
    "skf = StratifiedKFold(n_splits=K, random_state=int(time.time()), shuffle = False)    # random_state=1\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(X_scaled_train, y)):\n",
    "    print(' NN kfold: {}  of  {} : '.format(i+1, K))\n",
    "    X_train, X_valid = X_scaled_train[train_index,:], X_scaled_train[valid_index,:]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    X_test = X_scaled_test\n",
    "    \n",
    "    # 设置网络结构\n",
    "    model = get_model()\n",
    "    \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                patience=5, \n",
    "                                                verbose=0, \n",
    "                                                factor=0.6, \n",
    "                                                min_lr=0.0005)\n",
    "    # 训练网络\n",
    "    model.fit(X_train, \n",
    "              y_train, \n",
    "              batch_size = 128,\n",
    "              validation_data = (X_valid,y_valid),\n",
    "              class_weight={1:5, 0:1},\n",
    "              epochs = 100,\n",
    "              verbose = 0,\n",
    "              callbacks = [learning_rate_reduction])\n",
    "    \n",
    "    \n",
    "    # 预测训练集\n",
    "    pred_train = model.predict_proba(X_train)\n",
    "    print( \" Train Gini = \", eval_gini(y_train, NNPre_to_list(pred_train)) )\n",
    "    # 预测验证集\n",
    "    pred_valid = model.predict_proba(X_valid)\n",
    "    sub_train['pred'].iloc[valid_index] = NNPre_to_list(pred_valid) \n",
    "    print( \" Valid Gini = \", eval_gini(y_valid, NNPre_to_list(pred_valid)) )\n",
    "    # 预测测试集\n",
    "    pred_test = model.predict_proba(X_scaled_test)/K\n",
    "    sub['pred'] += NNPre_to_list(pred_test)\n",
    "    \n",
    "print( \"\\nGini for full training set:\" )\n",
    "print(eval_gini(y, sub_train.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train.to_csv(base_path+'result/NN_train.csv', index=False)\n",
    "sub.to_csv(base_path+'result/NN_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
